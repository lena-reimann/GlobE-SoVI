###################################################################
#### preprocess data of potential social vulnerability drivers ####
###################################################################
# by Lena Reimann
# May 31, 2023

# This script corresponds to the data processing described in '1) Vulnerability drivers' of
# Reimann et al. "An empirical social vulnerability map (‘GlobE-SoVI’) for flood risk assessment at global scale".
# The final output are global raster files (i.e. GeoTIFFs) of all potential social vulnerability drivers 
# explored in the study that had to be preprocessed to 30 arc seconds spatial resolution (i.e. 1. age and gender proportions; 
# 2. gap-filled income and education data; 3. education scaled by age)

rm(list=ls())

path = "./path_to_data"
lib = "./path_to_R_libraries"

# packages
library(sp, lib.loc = lib)
library(raster, lib.loc = lib)
library(terra, lib.loc = lib)
library(dplyr, lib.loc = lib)
library(sf, lib.loc = lib)
library(rgdal, lib.loc = lib)
library(igraph, lib.loc = lib)
library(iterators, lib.loc = lib)

#for parallel processing
library("parallel", lib.loc = lib)
library("foreach", lib.loc = lib)
library("doParallel", lib.loc = lib)
library("igraph", lib.loc = lib)
library("snow", lib.loc = lib)
library("doSNOW", lib.loc = lib)

cores = 2 # number of cores to use for parallel processing


####----------- 1.) Load data -------------####

## base data ##
# iso codes (https://sedac.ciesin.columbia.edu/data/set/gpw-v4-national-identifier-grid-rev11)
iso = read.csv(paste(path, "gpw_v4_national_identifier_grid_rev11_30_sec.csv", sep = "/")) # produced from available shapefile
iso = iso[, c("Value", "ISOCODE")]
iso_tif = rast(paste(path, "gpw_v4_national_identifier_grid_rev11_30_sec.tif", sep = "/"))


## age and gender ## 
# GPW v4.11 (https://sedac.ciesin.columbia.edu/data/set/gpw-v4-basic-demographic-characteristics-rev11)
file = "gpw_v4_basic_demographic_characteristics_rev11_"
data_type <- "cntm_30_sec"
t  <- 2010

# define ag to be loaded
ag1 <- sprintf("ag%s", seq(0,60, by= 5))
ag1[length(ag1)+1] <- paste0(sprintf("ag%s", length(ag1) * 5), "+")
ag1 = c(paste0(ag1, "f"), paste0(ag1, "m"))

ag2 <- sprintf("a0%s", seq(0,60, by= 5))
ag2[1:2] <- c("a000", "a005")
ag2[length(ag2)+1] <- paste0(sprintf("a0%s", length(ag2) * 5))

ag3 <- sprintf("0%s", seq(4,64, by= 5))
ag3[c(1:2)] <- c("004", "009")
ag3[length(ag3)+1] <- "plus"

ag_f <- stack(paste(paste(paste0(paste(path, file, sep = "/"), ag2, "_", ag3, "ft"), t, data_type, sep = "_"), 
                    "tif", sep = "."))
ag_m <- stack(paste(paste(paste0(paste(path, file, sep = "/"), ag2, "_", ag3, "mt"), t, data_type, sep = "_"), 
                    "tif", sep = "."))

# all age groups in one stack
ag <- stack(ag_f, ag_m)
remove(ag_f, ag_m)

# name layers
names(ag) = ag1


## education and income ##
# GDL data (https://globaldatalab.org/shdi/)
gdl <- read_sf(paste(path, "shdi2022_World_large.shp", sep = "/"))
shdi <- read.csv(paste(path, "SHDI-SGDI-Total 5.0.csv", sep = "/"), stringsAsFactors = F)

gdl_tif_ori = rast(paste(path, "gdl_admin_ids.tif", sep = "/")) # load raster produced from GDL admin units based on unique ids
gdl_tif_euc = rast(paste(path, "gdl_admin_eucl.tif", sep = "/")) # load raster produced from GDL admin units based on unique ids, extended with euclidean allocation to account for potential data mismatches e.g. in coastal areas

# load national-level HDI data (for gap-filling) (https://hdr.undp.org/data-center/human-development-index#/indicies/HDI)
hdi = read.csv(paste(path, "HDR21-22_edu+inc_2010.csv", sep = "/"), stringsAsFactors = F) # produced from Excel sheet


####------------------ 2.) Functions --------------------####

## age and gender ## 
# calculate AG or sex proportions (raster-based)
prop <- function(stack, aim)  { # input: rasters female and male combined in one stack; aim ("age" or "sex")
  require(raster)
  # if aim == sex make stack with sexes summed up
  if (aim == "sex") {
    # sum up all AGs per sex and stack again
    f = calc(stack[[1 : (nlayers(stack) / 2)]], fun = function(x) sum(x))
    m = calc(stack[[(nlayers(stack) / 2 + 1) : nlayers(stack)]], fun = function(x) sum(x))
    stack = stack(f, m)
  }
  
  # sum up all pop (cross-check for t2010)
  tot <- calc(stack, fun = function(x) sum(x))
  
  # calculate AG proportions per cell --> sum of all AG == 1
  prop <- overlay(stack, tot, fun = function(x,y) x / y)
  
  if (aim == "sex") {
    return(list(prop, stack))
  } else {
    return(list(prop, tot))
  }
}


## education and income ##
# 2010 gap filling
gap_fill_yrs <- function(shdi_db, shdi_yr, years, iso, var) {
  # fill gaps in years
  for (j in 1:length(years)) { 
    
    sub = subset(shdi_db, year == years[j] & iso_code == iso[i])
    
    if (sum(sub[,var[1]], na.rm = T) == 0 & j != length(years)) { # if data cannot be filled
      next
    } else if (nrow(sub) == 0) {
      shdi_yr[shdi_yr$iso_code == iso[i], var[3]] <- 0
      
      print(paste0("no replacement year"))
      break
    } else if (sum(sub[,var[1]], na.rm = T) == 0 & j == length(years)) {
      shdi_yr[shdi_yr$iso_code == iso[i], var[3]] <- rep(0, nrow(sub))
      
      print(paste0("no replacement year"))
      break
    } else {
      shdi_yr[shdi_yr$iso_code == iso[i], var[1]] <- sub[, var[1]]
      shdi_yr[shdi_yr$iso_code == iso[i], var[2]] <- sub[, var[2]]
      shdi_yr[shdi_yr$iso_code == iso[i], var[3]] <- rep(years[j], nrow(sub))
      
      print(paste0("taken ", years[j]))
      break
    }
  } # end of j loop

    return(shdi_yr)
}

# fill gaps in shdi data with national-level data from hdi and harmonize extents
fill_gap_r = function(subn_ori, nat, subn_euc) { #subnational raster (original and eucl allo) & national raster
  require(terra)
  
  # fill gaps with national-level data
  subn_gfil = merge(subn_ori, nat) # use as mask
  subn_gfil_eu = merge(subn_euc, nat)
  
  # mask gap-filled raster based on eucl with gap-filled raster without eucl
  subn_gfil = mask(subn_gfil_eu, subn_gfil)
  
  return(subn_gfil)
}

# scale MYS for different AGs
sc_edu = function(edu, ag, ag_name, path) { #input: stack of MYS and pop numbers per AG, vector with ag names, path to write to
  require(raster)
  
  for (i in 1:(nlayers(ag)/2)) {
    # extract f and m layers of the respective AG
    sex = stack(ag[[i]], ag[[nlayers(ag)/2 + i ]])
    
    # set edu to 0 where ag 0
    edu_ag = overlay(edu, sex, fun = function(x,y) {x[y==0] <- NA; return(x)})
    
    # multiplication factor
    fac = ifelse(i == 1, 0, (i - 0.5) / 5) #5 = AG interval
    
    # scale for the first 5 AGs
    if (i <= 5) {
      edu_ag = edu_ag * fac
    } else {
      edu_ag = edu_ag
    }
    
    # divide by 10 to get to YS and write
    edu_ag = calc(edu_ag, fun = function(x) {x / 10})
    
    # remove very high values instead of NAs in water cells
    edu_ag = calc(edu_ag, fun = function(x) {x[x>20] <- NA; return(x)})
    
    # write raster
    name = paste(paste("edu", c(ag_name[[i]], ag_name[[length(ag_name)/2 + i ]]), sep = "_"), "tif", sep = ".")
    name = paste(path, name, sep = "/")  
    writeRaster(edu_ag, filename = name, format = "GTiff", bylayer = T, overwrite = T)
  }
}


####------------------ 3.) Analysis --------------------####

### Step 1. process age and gender data ###

## AG proportions
prop <- prop(ag, "age") 
#prop_ag = prop[[1]]
#pop_tot = prop[[2]]

# write rasters
name = paste(ag1, "prop.tif", sep = "_")
name = paste(path, name, sep = "/")
writeRaster(prop[[1]], filename = name, format = "GTiff", bylayer = T, overwrite = T)


## calculate proportions of sexes
prop = prop(ag, "sex")

# write rasters
# proportions
name = c("f_prop.tif", "m_prop.tif")
name = paste(path, name, sep = "/")
writeRaster(prop[[1]], filename = name, format = "GTiff", bylayer = T, overwrite = T)


### Step 2. process GDL data ###

## Step 2a. gap filling
# select 2010
shdi2010 = shdi[which(shdi$year == 2010),]

# prep gap filling
iso_gdl = unique(shdi2010$iso_code)
yrs = c(rbind(seq(2011, 2019), seq(2009, 2001)))

# baseline year (will be replaced when using different year)
shdi2010$yr_edu <- 2010
shdi2010$yr_inc <- 2010

# define variables (column names)
edu = c("mschf", "mschm", "yr_edu")
inc = c("gnicf", "gnicm", "yr_inc")

# fill gaps
for (i in 1:length(iso_gdl)) { # check each cntr individually
  sub = subset(shdi2010, shdi2010$iso_code == iso_gdl[i])
  
  #education
  if (sum(sub[,edu[1]], na.rm = T) == 0) { # if 2010 data missing
    shdi2010 <- gap_fill_yrs(shdi, shdi2010, yrs, iso_gdl, edu)
  } else {
    print(paste0("2010 available"))
  }
  
  #income
  if (sum(sub[,inc[1]], na.rm = T) == 0) { # if 2010 data missing
    shdi2010 <- gap_fill_yrs(shdi, shdi2010, yrs, iso_gdl, inc)
  } else {
    print(paste0("2010 available"))
  }
} # end of i loop

# select columns
shdi2010 = data.frame(shdi2010[,4:5], shdi2010$continent, 
                      round(shdi2010$msch * 10, 0), round(shdi2010$mschf * 10, 0), round(shdi2010$mschm * 10,0), # multiply by 10 and round values to be able to create integer values in the rasters
                      round(shdi2010$gnic, 0), round(shdi2010$gnicf, 0), round(shdi2010$gnicm, 0), 
                      shdi2010$yr_edu, shdi2010$yr_inc)
colnames(shdi2010) = c("gdlcode", "level", "continent",
                       "msch", "mschf", "mschm", "gnic", "gnicf", "gnicm", "yr_edu", "yr_inc")

## Step 2b. replace NA for female versus male with national totals
shdi2010$edu_sex <- 1
shdi2010$inc_sex <- 1

# education
shdi2010[which(is.na(shdi2010$mschf)), "edu_sex"] <- 0
shdi2010[which(is.na(shdi2010$mschf)), "mschf"] <- shdi2010[which(is.na(shdi2010$mschf)), "msch"] 
shdi2010[which(is.na(shdi2010$mschm)), "mschm"] <- shdi2010[which(is.na(shdi2010$mschm)), "msch"] 

# income
shdi2010[which(is.na(shdi2010$gnicf)), "inc_sex"] <- 0
shdi2010[which(is.na(shdi2010$gnicf)), "gnicf"] <- shdi2010[which(is.na(shdi2010$gnicf)), "gnic"] 
shdi2010[which(is.na(shdi2010$gnicm)), "gnicm"] <- shdi2010[which(is.na(shdi2010$gnicm)), "gnic"] 

## Step 2c. merge with admin units
# add shape ids
id = seq(0, nrow(gdl)-1)
gdl = cbind(id, gdl)

# merge to polygons
glo_sf = merge(gdl[,-c(3)], shdi2010, by = ("gdlcode"), all = T)

# check for duplicates (due to all = T) and remove
dupl = glo_sf[which(glo_sf$gdlcode %in% gdl$gdlcode == F), ] #don't contain any geometries
glo_sf = glo_sf[-c(which(glo_sf$gdlcode %in% gdl$gdlcode == F)), ] #all geometries 

## Step 2d. rasterize admin units with the variables of interest

# extract relevant variables for reclassification (make sure that ids are aligned correctly)
vars = c("mschf", "mschm", "gnicf", "gnicm") #define variables

shdi = glo_sf[, c("id", vars)]
st_geometry(shdi) <- NULL

for (i in 1:length(vars)) {
  rcl = c(shdi$id, shdi[,vars[i]]) # determine reclass values
  rcl = matrix(rcl, ncol = 2) # make matrix
  
  name = paste0(path, "/", vars[i], "2010.tif")
  classify(gdl_tif_ori, rcl, filename = name, overwrite = T, datatype = "INT4U")
  
  name = paste0(path, "/", vars[i], "2010_eucl.tif")
  classify(gdl_tif_euc, rcl, filename = name, overwrite = T, datatype = "INT4U")
}

## 2e. process HDI data

# merge HDI with isos
hdi = merge(iso, hdi, by.x = "ISOCODE", by.y = "iso3", all.x = T)

# replace values in GRL and PRI with values from DK and US
hdi[which(hdi$ISOCODE == "GRL"), 4:11] <- hdi[which(hdi$ISOCODE == "DNK"), 4:11]
hdi[which(hdi$ISOCODE == "PRI"), 4:11] <- hdi[which(hdi$ISOCODE == "USA"), 4:11]

# fill gaps in gender-based edu and inc
hdi$edu_sex <- 1
hdi$inc_sex <- 1

#education
hdi[which(is.na(hdi$mschf)), "edu_sex"] <- 0
hdi[which(is.na(hdi$mschf)), "mschf"] <- hdi[which(is.na(hdi$mschf)), "msch"] 
hdi[which(is.na(hdi$mschm)), "mschm"] <- hdi[which(is.na(hdi$mschm)), "msch"] 

#income
hdi[which(is.na(hdi$gnicf)), "inc_sex"] <- 0
hdi[which(is.na(hdi$gnicf)), "gnicf"] <- hdi[which(is.na(hdi$gnicf)), "gnic"] 
hdi[which(is.na(hdi$gnicm)), "gnicm"] <- hdi[which(is.na(hdi$gnicm)), "gnic"] 


# multiply edu*10 and round
hdi$msch = round(hdi$msch * 10, 0)
hdi$mschf = round(hdi$mschf * 10, 0)
hdi$mschm = round(hdi$mschm * 10, 0)

# round inc
hdi$gnic = round(hdi$gnic, 0)
hdi$gnicf = round(hdi$gnicf, 0)
hdi$gnicm = round(hdi$gnicm, 0)

# reclassify iso_tif raster
for (i in 1:length(vars)) {
  rcl = c(hdi$Value, hdi[,vars[i]]) # determine reclass values
  rcl = matrix(rcl, ncol = 2) # make matrix
  
  name = paste0(path, "/hdi_", vars[i], "2010.tif")
  classify(iso_tif, rcl, filename = name, overwrite = T, datatype = "INT4U")
}

## 2f. fill GDL gaps

# for parallel processing
cl <- makeCluster(cores)
registerDoParallel(cl, cores = cores)

# fill gaps with HDI data
foreach (i = 1:length(vars),
         .packages = c("terra", "igraph", "dplyr")) %dopar%  {
           # load shdi rasters         
           name = paste0(path, "/", vars[i], "2010.tif")
           shdi = rast(name)
           
           name = paste0(path, "/", vars[i], "2010_eucl.tif")
           shdi_euc = rast(name)
           
           # load HDI rasters
           name = paste0(path, "/hdi_", vars[i], "2010.tif")
           hdi = rast(name)
           
           # fill shdi gaps
           shdi_gfil = fill_gap_r(shdi, hdi, shdi_euc)
           
           # path and vars need to be included here because otherwise not handed to each worker during parallel processing
           path = "./path_to_data"
           vars = c("mschf", "mschm", "gnicf", "gnicm")
           name = paste0(path, "/", vars[i], "2010.tif")
           writeRaster(shdi_gfil, filename = name, overwrite = T, datatype = "INT4U")
         }
stopCluster(cl)  # stop parallel processing


### Step 3. calculate scaled education ###

# load raster produced as output from Step 2
name = paste0(path, "/", vars[c(1,2)], "2010.tif")
file = paste(path, name, sep = "/")
edu = stack(file)

sc_edu(edu, ag, ag1, path) #scaled education per AG


####----------------------- continue with script 02 --------------------------####
  
